{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config Application.log_level=\"INFO\"\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig()\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "    data = np.loadtxt(file, delimiter=',', skiprows=1)\n",
    "    return data\n",
    "\n",
    "def split_data(data, ratio):\n",
    "    rows = data.shape[0]\n",
    "    rows = int(rows * ratio)\n",
    "    train_data, eval_data = np.split(data, [rows,], axis=0)\n",
    "    return train_data, eval_data\n",
    "\n",
    "def data_to_iter(data, batch_size=10):\n",
    "    y, x = np.split(data, [1], axis=1)\n",
    "    \n",
    "    y = y.flatten()\n",
    "    \n",
    "    data_iter = mx.io.NDArrayIter(\n",
    "        data=x,\n",
    "        label=y,\n",
    "        batch_size=batch_size,\n",
    "        last_batch_handle='drop',\n",
    "    )\n",
    "    \n",
    "    return data_iter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(context):\n",
    "    data = mx.sym.Variable('data')\n",
    "    label = mx.sym.Variable('softmax_label')\n",
    "    data = mx.sym.reshape(data=data, shape=[-1, 28, 28])\n",
    "    \n",
    "    net = mx.sym.FullyConnected(data, num_hidden=64)\n",
    "    net = mx.sym.Activation(net, act_type='relu')\n",
    "    net = mx.sym.FullyConnected(net, num_hidden=10)\n",
    "    net = mx.sym.SoftmaxOutput(net, label, preserve_shape=True, name='softmax')\n",
    "    \n",
    "    model = mx.mod.Module(\n",
    "        symbol=net,\n",
    "        context=context,\n",
    "        data_names=['data'],\n",
    "        label_names=['softmax_label'],\n",
    "        logger=logger,\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_prediction(predictions):\n",
    "    best_prediction = max(\n",
    "        enumerate(predictions), \n",
    "        key = lambda x: x[1]\n",
    "    )\n",
    "    label = best_prediction[0]\n",
    "    \n",
    "    return label\n",
    "    \n",
    "\n",
    "def visualize_prediction(datum, predictions):\n",
    "    label = int(datum[0])\n",
    "    datum = datum[1:]\n",
    "    \n",
    "    image = datum.reshape(28, 28)\n",
    "    \n",
    "    prediction = best_prediction(predictions)\n",
    "    \n",
    "    plt.title(\"Label: {}, Prediction: {}\".format(label, prediction))\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data('train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, eval_data = split_data(data, 0.8)\n",
    "\n",
    "train_iter = data_to_iter(train_data)\n",
    "eval_iter = data_to_iter(eval_data)\n",
    "\n",
    "print(\"Training data shape:\", train_data.shape)\n",
    "print(\"Evaluation data shape:\", eval_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(mx.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Predicting with an untrained model\n",
    "\n",
    "The model (mx.Module) needs to be bound to certain data shapes\n",
    "to bootstrap the symbol to proper data shapes\n",
    "\n",
    "Then the model is initialized with normally distributed noise\n",
    "\n",
    "Initialized model can be used to predict as well =D\n",
    "\"\"\"\n",
    "\n",
    "data_iter = data_to_iter(data)\n",
    "\n",
    "model.bind(\n",
    "    data_shapes=data_iter.provide_data,\n",
    "    force_rebind=True,\n",
    "    label_shapes=data_iter.provide_label,\n",
    "    for_training=False,\n",
    ")\n",
    "\n",
    "model.init_params(\n",
    "    mx.initializer.Normal(),\n",
    "    force_init=True,\n",
    ")\n",
    "\n",
    "model.score(data_iter, ['loss', 'acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_data=train_iter,\n",
    "    eval_data=eval_iter,\n",
    "    optimizer='sgd',\n",
    "    optimizer_params={'learning_rate':0.001},\n",
    "    eval_metric=['acc'],\n",
    "    num_epoch=10,\n",
    "    force_init=True,\n",
    "    force_rebind=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(data_iter, ['loss', 'acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100, 120):\n",
    "    visualize_prediction(data[i], predictions[i])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
