{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow.data as tf_data\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.regularizers as regularizers\n",
    "import tensorflow.train as train\n",
    "import tensorflow.keras.layers as layers\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "    data = np.loadtxt(file, delimiter=',', skiprows=1)\n",
    "    return data\n",
    "\n",
    "def split_train_eval(data, ratio):\n",
    "    rows = data.shape[0]\n",
    "    rows = int(rows * ratio)\n",
    "    train_data, eval_data = np.split(data, [rows,], axis=0)\n",
    "    \n",
    "    return train_data, eval_data\n",
    "\n",
    "def split_x_y(data):\n",
    "    x = data[:, 1:]/256\n",
    "    y = data[:, :1]\n",
    "    \n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    \n",
    "    return x, y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    model.add(layers.Reshape((28, 28, 1), input_shape=(784, )))\n",
    "    model.add(layers.Conv2D(filters=25, kernel_size=5, activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=train.AdamOptimizer(0.001, ),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEnsemble(object):\n",
    "    def __init__(self, *models):\n",
    "        self._models = models\n",
    "    \n",
    "    @staticmethod\n",
    "    def _predict(models, x):\n",
    "        for datum in x:\n",
    "            datum = datum.reshape(1, -1)\n",
    "            \n",
    "            prediction = [\n",
    "                model.predict(datum)\n",
    "                for model in models\n",
    "            ]\n",
    "\n",
    "            prediction = np.average(prediction, axis=0)            \n",
    "            prediction = np.argmax(prediction, axis=1)\n",
    "            \n",
    "            yield prediction\n",
    "            \n",
    "    def evaluate(self, x, y):\n",
    "        score = 0\n",
    "\n",
    "        for prediction, label in zip(\n",
    "            self._predict(self._models, x),\n",
    "            y\n",
    "        ):\n",
    "            if prediction != label:\n",
    "                continue\n",
    "                \n",
    "            score += 1\n",
    "        \n",
    "        return score / x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_prediction(datum, predictions):\n",
    "    label = int(datum[0])\n",
    "    datum = datum[1:]\n",
    "    \n",
    "    image = datum.reshape(28, 28)\n",
    "    \n",
    "    prediction = np.argmax(predictions)\n",
    "    \n",
    "    plt.title(\"Label: {}, Prediction: {}\".format(label, prediction))\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data('train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33600, 784)\n",
      "(33600, 1)\n",
      "(8400, 784)\n",
      "(8400, 1)\n"
     ]
    }
   ],
   "source": [
    "train_data, eval_data = split_train_eval(data, 0.8)\n",
    "\n",
    "train_x, train_y = split_x_y(train_data)\n",
    "eval_x, eval_y = split_x_y(eval_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 1\n",
      "Training model 2\n",
      "Training model 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0d3d0b1d30>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Training model 1')\n",
    "model_1 = build_model()\n",
    "model_1.fit(x=train_x, y=train_y, batch_size=100, epochs=10, validation_data=[eval_x, eval_y], shuffle=True, verbose=0)\n",
    "\n",
    "print('Training model 2')\n",
    "model_2 = build_model()\n",
    "model_2.fit(x=train_x, y=train_y, batch_size=100, epochs=10, validation_data=[eval_x, eval_y], shuffle=True, verbose=0)\n",
    "\n",
    "print('Training model 3')\n",
    "model_3 = build_model()\n",
    "model_3.fit(x=train_x, y=train_y, batch_size=100, epochs=10, validation_data=[eval_x, eval_y], shuffle=True, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = ModelEnsemble(model_1, model_2, model_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 validation score:\n",
      "8400/8400 [==============================] - 1s 89us/sample - loss: 0.0658 - acc: 0.9818\n",
      "Model 2 validation score:\n",
      "8400/8400 [==============================] - 1s 87us/sample - loss: 0.0782 - acc: 0.9802\n",
      "Model 3 validation score:\n",
      "8400/8400 [==============================] - 1s 90us/sample - loss: 0.0706 - acc: 0.9804\n",
      "Ensemble validation score:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9833333333333333"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Model 1 validation score:')\n",
    "model_1.evaluate(eval_x, eval_y)\n",
    "\n",
    "print('Model 2 validation score:')\n",
    "model_2.evaluate(eval_x, eval_y)\n",
    "\n",
    "print('Model 3 validation score:')\n",
    "model_3.evaluate(eval_x, eval_y)\n",
    "\n",
    "print('Ensemble validation score:')\n",
    "ensemble.evaluate(eval_x, eval_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
